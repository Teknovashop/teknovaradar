name: Radar Tecnológico (daily)

on:
  schedule:
    - cron: "15 6 * * *"   # 06:15 UTC, ajusta si quieres
  workflow_dispatch:

jobs:
  run:
    runs-on: ubuntu-latest
    permissions:
      contents: read

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install deps
        run: |
          python -m pip install --upgrade pip
          pip install requests

      # -------- TED (UE) ----------
      - name: Scraper TED (UE)
        run: python scraper/scraper_radar.py
        continue-on-error: true
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_SERVICE_ROLE: ${{ secrets.SUPABASE_SERVICE_ROLE }}

      # -------- Diagnóstico PLACSP (feeds e items) ----------
      - name: Diagnóstico PLACSP (feeds e items)
        continue-on-error: true
        run: |
          python - << 'PY'
          import os, requests, xml.etree.ElementTree as ET
          UA = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) Radar-Diag/1.1",
            "Accept": "application/atom+xml, application/rss+xml, application/xml, text/xml, */*",
            "Accept-Language": "es-ES,es;q=0.9",
            "Referer": "https://www.contrataciondelestado.es/"
          }
          feeds = os.environ.get("PLACSP_FEEDS","").strip()
          print("[DIAG] PLACSP_FEEDS presente:", bool(feeds))
          lst = [u.strip() for u in feeds.split(",") if u.strip()]
          print("[DIAG] Nº feeds:", len(lst))
          if not lst:
              print("[DIAG] Falta PLACSP_FEEDS. Ejemplo: https://www.contrataciondelestado.es/sindicacion/sindicacion_1050.atom")
          else:
              url = lst[0]
              print("[DIAG] Primer feed:", url)
              r = requests.get(url, timeout=60, headers=UA, allow_redirects=True)
              print("[DIAG] HTTP status:", r.status_code, "bytes:", len(r.content))
              text = r.content[:200].strip().lower()
              if text.startswith(b"<!doctype html") or b"<html" in text:
                  print("[DIAG] Parece HTML (portal). El scraper hará reintentos con variantes y proxy.")
              else:
                  try:
                      ET.fromstring(r.content)
                      print("[DIAG] XML válido ✔")
                  except Exception as e:
                      print("[DIAG] No es XML válido:", e)
          PY
        env:
          PLACSP_FEEDS: ${{ secrets.PLACSP_FEEDS }}

      # -------- Scraper España (PLACSP) ----------
      - name: Scraper España (PLACSP)
        run: python scraper/scraper_spain_placsp.py
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_SERVICE_ROLE: ${{ secrets.SUPABASE_SERVICE_ROLE }}
          PLACSP_FEEDS: ${{ secrets.PLACSP_FEEDS }}
          STRICT_FILTER: "false"   # luego cámbialo a "true"
          MAX_ITEMS: "150"
